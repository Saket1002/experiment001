{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saket1002/experiment001/blob/master/Ridge%2C_Lasso_and_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJB6X_mVxK_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nqYSUVLm68N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyzB3QMAwhe3",
        "outputId": "e0200408-cf05-4a33-cfd4-caf5694c8091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "range(1, 100)\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "https://medium.com/towards-data-science/ridge-regression-for-better-usage-2f19b3a202db\n",
        "\n"
      ],
      "metadata": {
        "id": "g2VIPc0T6yLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression is a variation of linear regression.\n",
        "\n",
        "\n",
        "OLS - Ordinary least square method is good old Linear Regression where optimization objective is to minimuze the sqare error.\n",
        "\n",
        "Overfitting - underfitting and just the right fitting.\n",
        "\n",
        "When a model can't capture the general underlying pattern from the data - its called underfitted model (aka high bias)\n",
        "\n",
        "When a model also learns the noise present in specific data set its called overfitting. (aka high variance)\n",
        "\n",
        "Case of overfitting is also called high variance as any noise in data is learned by model and hence a slightly different set of data can generate different model.\n",
        "\n",
        "\n",
        "Just the right fit : this is the target state for each model. This is where model has learned the underlying pattern but not noise.\n",
        "\n",
        "Training set error reduces as we move from underfit, just the right fit to over fit. However just the right fit perform the best for new/ test  data.  \n",
        "\n",
        "\n",
        "\n",
        "Least square method finds the best and *ubiased* (?) coefficients.\n",
        "\n",
        "unbiased here means OLS doesn't coonsider which independent variable is more important than others. Well this is very confusing. Doesn't different value of cofficient automatically suggest the relative importance of the feature ?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wCmRYsso7TaO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNTey/upYNvWjCa9atMeqKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}